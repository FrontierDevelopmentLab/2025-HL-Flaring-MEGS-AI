{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Process AIA Data, check for NaN values, normalize the data by dividing the\n",
    "exposure time, plot the histograms to check for saturation levels."
   ],
   "id": "4caa9f15f1590dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import libraries\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido, attrs as a\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "98a9f3520f2b163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Trying out simple plotting with one FITs file**",
   "id": "50a24ac13ab2d277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "file = \"/mnt/data/SDO-AIA/94/2023-08-05T21:10:00.fits\"",
   "id": "d136fe618bbc13ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sunpy.map\n",
    "import numpy as np\n",
    "\n",
    "file = \"/mnt/data/SDO-AIA/94/2023-08-05T21:10:00.fits\"\n",
    "aia_map = sunpy.map.Map(file)\n",
    "data = aia_map.data.flatten()\n",
    "# Check for NaNs\n",
    "num_nans = np.isnan(data).sum()\n",
    "print(f\"Number of NaNs: {num_nans}\")\n",
    "# Check for infinities\n",
    "num_infs = np.isinf(data).sum()\n",
    "print(f\"Number of infinite values: {num_infs}\")\n",
    "# Check min and max values\n",
    "print(f\"Data min: {np.nanmin(data)}\")\n",
    "print(f\"Data max: {np.nanmax(data)}\")"
   ],
   "id": "f35144e92f59e3d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "aia_map = sunpy.map.Map(file)\n",
    "aia_map.plot()\n",
    "plt.colorbar()\n",
    "plt.title('AIA 94 Å')\n",
    "plt.show()"
   ],
   "id": "656806ba871728d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.colors as colors\n",
    "from sunpy.visualization.colormaps import color_tables as ct\n",
    "aia_map.plot(norm=colors.LogNorm(vmin=10, vmax=aia_map.data.max()))\n",
    "plt.colorbar()\n",
    "plt.title('AIA 94 Å (Log Scale)')\n",
    "plt.show()"
   ],
   "id": "6694232e410d6935"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sunpy.visualization.colormaps import color_tables as ct\n",
    "import astropy.units as u\n",
    "# Check data positivity\n",
    "print(f\"Min of aia_map.data: {aia_map.data.min()}\")\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(projection=aia_map)\n",
    "im = aia_map.plot(cmap=ct.aia_color_table(94 * u.angstrom),\n",
    "             norm=colors.LogNorm(vmin=10, vmax=aia_map.data.max()))\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.title('AIA 94 Å (Log Scale)')\n",
    "plt.show()"
   ],
   "id": "88a6a43519255911"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aia_map.data",
   "id": "6eb06a4a906c7f5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.imshow(aia_map.data)",
   "id": "73ba1b5196154e18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "sample_size = 1000  # number of files to sample\n",
    "max_workers = 8  # optional for parallelization later\n",
    "\n",
    "# Collect and sample FITS files\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "if len(fits_files) < sample_size:\n",
    "    sample_files = fits_files\n",
    "else:\n",
    "    sample_files = random.sample(fits_files, sample_size)\n",
    "\n",
    "total_files = 0\n",
    "total_pixels = 0\n",
    "total_nans = 0\n",
    "files_with_nans = []\n",
    "\n",
    "print(f\"Checking for NaN values in {len(sample_files)} randomly sampled FITS files:\\n\")\n",
    "\n",
    "for file in tqdm(sample_files, desc=\"Checking NaNs\"):\n",
    "    try:\n",
    "        with fits.open(file, memmap=True) as hdul:\n",
    "            data = hdul[1].data if len(hdul) > 1 else hdul[0].data\n",
    "            num_pixels = data.size\n",
    "            num_nans = np.isnan(data).sum()\n",
    "        if num_nans > 0:\n",
    "            print(f\"{file.name}: NaNs = {num_nans} / {num_pixels} \"\n",
    "                  f\"({(num_nans / num_pixels * 100):.6f}%)\")\n",
    "            files_with_nans.append(file.name)\n",
    "        total_files += 1\n",
    "        total_pixels += num_pixels\n",
    "        total_nans += num_nans\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Failed to process - {e}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total sampled files checked: {total_files}\")\n",
    "print(f\"Total pixels checked: {total_pixels}\")\n",
    "print(f\"Total NaNs found: {total_nans} \"\n",
    "      f\"({(total_nans / total_pixels * 100 if total_pixels else 0):.6f}%)\")\n",
    "if files_with_nans:\n",
    "    print(\"\\nFiles with NaNs:\")\n",
    "    for fname in files_with_nans:\n",
    "        print(f\" - {fname}\")\n",
    "else:\n",
    "    print(\"\\nNo files with NaNs detected in the sampled set.\")"
   ],
   "id": "842b23dcdc64b445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def check_nan_in_wavelength_folder(folder_path, wavelength, sample_size=1000):\n",
    "    folder = Path(folder_path)\n",
    "    fits_files = sorted(folder.glob(\"*.fits\"))\n",
    "\n",
    "    if len(fits_files) == 0:\n",
    "        print(f\"No FITS files found in {folder_path}\")\n",
    "        return\n",
    "    if len(fits_files) < sample_size:\n",
    "        sample_files = fits_files\n",
    "    else:\n",
    "        sample_files = random.sample(fits_files, sample_size)\n",
    "    total_files = 0\n",
    "    total_pixels = 0\n",
    "    total_nans = 0\n",
    "    files_with_nans = []\n",
    "    print(f\"\\nChecking NaN values for AIA {wavelength} Å ({len(sample_files)} sampled files):\")\n",
    "\n",
    "    for file in tqdm(sample_files, desc=f\"Checking {wavelength} Å\"):\n",
    "        try:\n",
    "            with fits.open(file, memmap=True) as hdul:\n",
    "                data = hdul[1].data if len(hdul) > 1 else hdul[0].data\n",
    "                num_pixels = data.size\n",
    "                num_nans = np.isnan(data).sum()\n",
    "\n",
    "            if num_nans > 0:\n",
    "                print(f\"{file.name}: NaNs = {num_nans} / {num_pixels} \"\n",
    "                      f\"({(num_nans / num_pixels * 100):.6f}%)\")\n",
    "                files_with_nans.append(file.name)\n",
    "            total_files += 1\n",
    "            total_pixels += num_pixels\n",
    "            total_nans += num_nans\n",
    "        except Exception as e:\n",
    "            print(f\"{file.name}: Failed to process - {e}\")\n",
    "\n",
    "    print(f\"\\nSummary for {wavelength} Å:\")\n",
    "    print(f\"Total sampled files checked: {total_files}\")\n",
    "    print(f\"Total pixels checked: {total_pixels}\")\n",
    "    print(f\"Total NaNs found: {total_nans} \"\n",
    "          f\"({(total_nans / total_pixels * 100 if total_pixels else 0):.6f}%)\")\n",
    "    if files_with_nans:\n",
    "        print(f\"\\nFiles with NaNs in {wavelength} Å:\")\n",
    "        for fname in files_with_nans:\n",
    "            print(f\" - {fname}\")\n",
    "    else:\n",
    "        print(f\"\\nNo files with NaNs detected in the sampled set for {wavelength} Å.\")\n",
    "\n",
    "#for reproducible sampling\n",
    "# random.seed(42)\n",
    "# Define your wavelength folders\n",
    "base_path = \"/mnt/data/SDO-AIA\"\n",
    "wavelength_folders = {\n",
    "    \"94\": f\"{base_path}/94\",\n",
    "    \"131\": f\"{base_path}/131\",\n",
    "    \"171\": f\"{base_path}/171\",\n",
    "    \"193\": f\"{base_path}/193\",\n",
    "    \"211\": f\"{base_path}/211\",\n",
    "    \"304\": f\"{base_path}/304\",\n",
    "}\n",
    "\n",
    "# Run check for each wavelength\n",
    "for wavelength, folder_path in wavelength_folders.items():\n",
    "    check_nan_in_wavelength_folder(folder_path, wavelength, sample_size=1000)"
   ],
   "id": "91f494d4d89ede60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we want to Normalize the exposure  by dividing all the pixel intensities values by expose value",
   "id": "f324beb68fec6e9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## check start and end dates in the folder\n",
    "import datetime\n",
    "# Folder path\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "# Collect all FITS files\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "dates = []\n",
    "for file in fits_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        fname = file.stem  # removes .fits\n",
    "        # Example: '2023-08-05T21:10:00'\n",
    "        date_part = fname.split(\".\")[0]\n",
    "        dt = datetime.fromisoformat(date_part)\n",
    "        dates.append(dt)\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Skipped - {e}\")\n",
    "if dates:\n",
    "    first_date = min(dates)\n",
    "    last_date = max(dates)\n",
    "    print(\"Based on filenames:\")\n",
    "    print(f\"First (earliest) file date: {first_date.isoformat()}\")\n",
    "    print(f\"Last (latest) file date:    {last_date.isoformat()}\")\n",
    "    print(f\"Total files scanned: {len(dates)}\")"
   ],
   "id": "8b3ef7b1f5e56b67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Select the specific days for the normalization and histogram plot\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your target dates\n",
    "target_dates = {\n",
    "    \"2023-07-02\",\n",
    "    \"2023-07-15\",\n",
    "    \"2023-07-31\",\n",
    "    \"2023-08-13\"\n",
    "}\n",
    "\n",
    "# Folder containing your FITS files\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "specific_dates_files = []\n",
    "for file in fits_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        fname = file.stem  # '2023-07-02T21:10:00'\n",
    "        date_str = fname.split(\"T\")[0]  # '2023-07-02'\n",
    "        if date_str in target_dates:\n",
    "            specific_dates_files.append(file)\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Skipped - {e}\")\n",
    "print(f\"\\nTotal files matching the selected target dates: {len(specific_dates_files)}\")\n",
    "# print(\"Examples:\")\n",
    "# for f in specific_dates_files[:10]:\n",
    "#     print(f\" - {f.name}\")"
   ],
   "id": "44c80c458d406030"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalize the target_dates FITS files",
   "id": "fd194629cddc8bd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Apply Normalization Step\n",
    "\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define target dates\n",
    "target_dates = {\n",
    "    \"2023-07-02\",\n",
    "    \"2023-07-15\",\n",
    "    \"2023-07-31\",\n",
    "    \"2023-08-13\"\n",
    "}\n",
    "\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "specific_dates_files = []\n",
    "for file in tqdm(fits_files, desc=\"Filtering files by date\", leave=True):\n",
    "    try:\n",
    "        fname = file.stem\n",
    "        if \"T\" in fname:\n",
    "            date_str = fname.split(\"T\")[0]\n",
    "            if date_str in target_dates:\n",
    "                specific_dates_files.append(file)\n",
    "        else:\n",
    "            tqdm.write(f\"{file.name}: Filename does not contain 'T', skipped.\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"{file.name}: Error during date parsing - {e}\")\n",
    "        continue\n",
    "print(f\"\\nTotal files matching target dates: {len(specific_dates_files)}\")\n",
    "\n",
    "## Normalization\n",
    "all_normalized_data = []\n",
    "for file in tqdm(specific_dates_files, desc=\"Normalizing FITS files\", leave=True):\n",
    "    try:\n",
    "        aia_map = sunpy.map.Map(file)\n",
    "        exptime = aia_map.exposure_time.value\n",
    "        normalized_data = aia_map.data / exptime\n",
    "        ## Mask invalid values\n",
    "        normalized_data = normalized_data[np.isfinite(normalized_data)]\n",
    "        normalized_data = normalized_data[normalized_data > 0]\n",
    "        all_normalized_data.append(normalized_data)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"{file.name}: Failed during normalization - {e}\")\n",
    "        continue\n",
    "if all_normalized_data:\n",
    "    try:\n",
    "        combined_data = np.concatenate(all_normalized_data)\n",
    "        print(f\"\\nTotal valid normalized pixels collected: {combined_data.size}\")\n",
    "    except MemoryError as e:\n",
    "        print(\"\\nMemoryError: Too many pixels to concatenate. Consider downsampling per file.\")\n",
    "else:\n",
    "    print(\"\\nNo valid data collected after normalization.\")"
   ],
   "id": "a363cf2dc1b4cece"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "##Get the exposure time with SunPy for A94 folder data\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Folder with your AIA 94 Å files\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "\n",
    "# Example: Compute and print the mean normalized intensity for each file\n",
    "for file in tqdm(fits_files, desc=\"Normalizing AIA 94 wavelength by exposure time\"):\n",
    "    try:\n",
    "        aia_map = sunpy.map.Map(file)\n",
    "        exptime = aia_map.exposure_time.value  # in seconds\n",
    "        # Normalize pixel data\n",
    "        normalized_data = aia_map.data / exptime\n",
    "        # Clean NaNs/Infs if needed\n",
    "        normalized_data = normalized_data[np.isfinite(normalized_data)]\n",
    "        normalized_data = normalized_data[normalized_data > 0]\n",
    "        # Example: Print mean normalized intensity\n",
    "        mean_val = np.mean(normalized_data)\n",
    "        print(f\"{file.name}: Mean normalized intensity = {mean_val:.2f}\")\n",
    "        #If we want to save normalized FITS for ML pipelines or consistency:\n",
    "        # from astropy.io import fits\n",
    "        # hdu = fits.PrimaryHDU(normalized_data, header=aia_map.meta)\n",
    "        # hdu.writeto(f\"/mnt/data/SDO-AIA/94_normalized/{file.name}\", overwrite=True)\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Failed - {e}\")"
   ],
   "id": "634ff66cf075e9f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## plot the basic histogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Flatten the data and remove NaNs for a clean histogram\n",
    "data = aia_map.data.flatten()\n",
    "data = data[~np.isnan(data)]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data, bins=500, color='gray')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Histogram of AIA Map Data')\n",
    "plt.show()"
   ],
   "id": "9a2106c60dd38b7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## plot the log-log histogram\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = aia_map.data.flatten()\n",
    "data = data[~np.isnan(data)]\n",
    "data = data[data > 0]  # Log requires positive values\n",
    "plt.figure()\n",
    "# Compute histogram without plotting first to enable log scale handling\n",
    "counts, bins = np.histogram(data, bins=500)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "plt.plot(bin_centers, counts)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Pixel Intensity (log scale)')\n",
    "plt.ylabel('Number of Pixels (log scale)')\n",
    "plt.title('Log-Log Histogram of AIA Map Data')\n",
    "plt.show()"
   ],
   "id": "27df31196b0bdd69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "accordion = widgets.Accordion(children=[log_output])\n",
    "accordion.set_title(0, 'Test Dropdown')\n",
    "accordion.selected_index = None\n",
    "display(accordion)\n",
    "with log_output:\n",
    "    print(\"If you see this message inside a collapsible box, ipywidgets is working.\")"
   ],
   "id": "46975db04c8bf32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "accordion = widgets.Accordion(children=[log_output])\n",
    "accordion.set_title(0, 'Progress Details')\n",
    "accordion.selected_index = None\n",
    "display(accordion)\n",
    "\n",
    "for i in tqdm(range(5), desc=\"Test Progress\"):\n",
    "    with log_output:\n",
    "        print(f\"Processing step {i+1}/5\")\n",
    "    time.sleep(0.5)"
   ],
   "id": "a3a70edaee37edff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sunpy.map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_aia_folder_histogram(\n",
    "    folder_path,\n",
    "    num_bins=500,\n",
    "    min_intensity=1,\n",
    "    max_intensity=1e4,\n",
    "    wavelength=\"94 Å\",\n",
    "    figsize=(14, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Incrementally process all FITS files in folder_path,\n",
    "    plot normal + log-log histograms without memory overflow.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str or Path): Path to the folder containing FITS files.\n",
    "        num_bins (int): Number of histogram bins.\n",
    "        min_intensity (float): Minimum intensity for binning (avoids log issues).\n",
    "        max_intensity (float): Maximum intensity for binning.\n",
    "        wavelength (str): For labeling plots.\n",
    "        figsize (tuple): Figure size.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    fits_files = sorted(folder.glob(\"*.fits\"))\n",
    "\n",
    "    # Collapsible log setup\n",
    "    log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "    accordion = widgets.Accordion(children=[log_output])\n",
    "    accordion.set_title(0, 'Detailed FITS File Processing Log')\n",
    "    accordion.selected_index = None\n",
    "    display(accordion)\n",
    "\n",
    "    bins = np.logspace(np.log10(min_intensity), np.log10(max_intensity), num_bins + 1)\n",
    "    combined_counts = np.zeros(num_bins)\n",
    "\n",
    "    for file in tqdm(fits_files, desc=f\"Processing {wavelength} FITS files\"):\n",
    "        try:\n",
    "            aia_map = sunpy.map.Map(file)\n",
    "            data = aia_map.data.flatten()\n",
    "\n",
    "            num_nans = np.isnan(data).sum()\n",
    "            num_infs = np.isinf(data).sum()\n",
    "            data_min = np.nanmin(data)\n",
    "            data_max = np.nanmax(data)\n",
    "\n",
    "            with log_output:\n",
    "                print(f\"{file.name}: NaNs={num_nans}, Infs={num_infs}, Min={data_min}, Max={data_max}\")\n",
    "\n",
    "            data = data[~np.isnan(data)]\n",
    "            data = data[~np.isinf(data)]\n",
    "            data = data[data > 0]\n",
    "\n",
    "            counts, _ = np.histogram(data, bins=bins)\n",
    "            combined_counts += counts\n",
    "\n",
    "        except Exception as e:\n",
    "            with log_output:\n",
    "                print(f\"{file.name}: Failed to process - {e}\")\n",
    "\n",
    "    if combined_counts.sum() == 0:\n",
    "        with log_output:\n",
    "            print(\"No valid data collected for histogram.\")\n",
    "        return\n",
    "\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # Normal histogram\n",
    "    axs[0].plot(bin_centers, combined_counts, lw=1)\n",
    "    axs[0].set_xlabel('Pixel Intensity')\n",
    "    axs[0].set_ylabel('Number of Pixels')\n",
    "    axs[0].set_title(f'Normal Histogram of AIA {wavelength} Data')\n",
    "    axs[0].grid(True, ls=\":\")\n",
    "\n",
    "    # Log-log histogram\n",
    "    axs[1].plot(bin_centers, combined_counts, lw=1)\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].set_xlabel('Pixel Intensity (log scale)')\n",
    "    axs[1].set_ylabel('Number of Pixels (log scale)')\n",
    "    axs[1].set_title(f'Log-Log Histogram of AIA {wavelength} Data')\n",
    "    axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "c36f2b37c6e4477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_aia_folder_histogram(\n",
    "    folder_path=\"/mnt/data/SDO-AIA/94\",\n",
    "    num_bins=500,\n",
    "    min_intensity=1,\n",
    "    max_intensity=1e4,\n",
    "    wavelength=\"94 Å\"\n",
    ")"
   ],
   "id": "197365a5ee0aa830"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41bbcac17565f173"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
