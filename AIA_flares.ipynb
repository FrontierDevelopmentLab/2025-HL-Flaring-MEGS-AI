{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Process AIA Data, check for NaN values, normalize the data by dividing the\n",
    "exposure time, plot the histograms to check for saturation levels."
   ],
   "id": "cb65837289466ab8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import libraries\n",
    "from astropy.io import fits\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido, attrs as a\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np"
   ],
   "id": "c2ee64ec18d35f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import astropy\n",
    "print(astropy.__version__)"
   ],
   "id": "483647fd53f2bcb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Trying out simple plotting with one FITs file**",
   "id": "c638107f0cdabbb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "file = \"/mnt/data/SDO-AIA/94/2023-08-05T21:10:00.fits\"",
   "id": "7485e8cbf3106876"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sunpy.map\n",
    "import numpy as np\n",
    "\n",
    "file = \"/mnt/data/SDO-AIA/94/2023-08-05T21:10:00.fits\"\n",
    "aia_map = sunpy.map.Map(file)\n",
    "data = aia_map.data.flatten()\n",
    "# Check for NaNs\n",
    "num_nans = np.isnan(data).sum()\n",
    "print(f\"Number of NaNs: {num_nans}\")\n",
    "# Check for infinities\n",
    "num_infs = np.isinf(data).sum()\n",
    "print(f\"Number of infinite values: {num_infs}\")\n",
    "# Check min and max values\n",
    "print(f\"Data min: {np.nanmin(data)}\")\n",
    "print(f\"Data max: {np.nanmax(data)}\")"
   ],
   "id": "5fa7fe232596ef7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "aia_map = sunpy.map.Map(file)\n",
    "aia_map.plot()\n",
    "plt.colorbar()\n",
    "plt.title('AIA 94 Å')\n",
    "plt.show()"
   ],
   "id": "ed8b1a70b10919f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.colors as colors\n",
    "from sunpy.visualization.colormaps import color_tables as ct\n",
    "aia_map.plot(norm=colors.LogNorm(vmin=10, vmax=aia_map.data.max()))\n",
    "plt.colorbar()\n",
    "plt.title('AIA 94 Å (Log Scale)')\n",
    "plt.show()"
   ],
   "id": "6b5c3ca434275384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sunpy.visualization.colormaps import color_tables as ct\n",
    "import astropy.units as u\n",
    "# Check data positivity\n",
    "print(f\"Min of aia_map.data: {aia_map.data.min()}\")\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(projection=aia_map)\n",
    "im = aia_map.plot(cmap=ct.aia_color_table(94 * u.angstrom),\n",
    "             norm=colors.LogNorm(vmin=10, vmax=aia_map.data.max()))\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.title('AIA 94 Å (Log Scale)')\n",
    "plt.show()"
   ],
   "id": "e1a18251c3c520d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aia_map.data",
   "id": "d900e1099256a290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot 92Å wavelength data folders histogram to look for saturation",
   "id": "4be48b965f49632"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check data information\n",
    "from astropy.io import fits\n",
    "file = \"/mnt/data/SDO-AIA/94/2023-08-07T19:30:00.fits\"\n",
    "with fits.open(file) as hdul:\n",
    "    hdul.info()"
   ],
   "id": "2976d6343162a8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = \"/mnt/data/SDO-AIA/94\"\n",
    "file_pattern = \"*.fits\"\n",
    "file_list = glob.glob(os.path.join(data_dir, file_pattern))\n",
    "\n",
    "valid_files = []\n",
    "empty_data_files = []\n",
    "unreadable_files = []\n",
    "hdu_summary = {}\n",
    "\n",
    "print(f\"Scanning {len(file_list)} FITS files...\\n\")\n",
    "\n",
    "for file in tqdm(file_list, desc=\"Processing FITS files\"):\n",
    "    try:\n",
    "        with fits.open(file, memmap=True) as hdul:\n",
    "            found = False\n",
    "            for idx, hdu in enumerate(hdul):\n",
    "                if hasattr(hdu, 'data') and hdu.data is not None:\n",
    "                    shape = hdu.data.shape\n",
    "                    found = True\n",
    "                    valid_files.append((file, idx, shape))\n",
    "                    key = f\"HDU{idx} shape={shape}\"\n",
    "                    hdu_summary[key] = hdu_summary.get(key, 0) + 1\n",
    "                    break  # Use the first HDU with valid image data\n",
    "            if not found:\n",
    "                empty_data_files.append(file)\n",
    "    except Exception:\n",
    "        unreadable_files.append(file)\n",
    "\n",
    "print(f\"\\nFiles with usable data: {len(valid_files)}\")\n",
    "print(f\"Files with no data: {len(empty_data_files)}\")\n",
    "print(f\"Unreadable FITS files: {len(unreadable_files)}\")\n",
    "\n",
    "print(\"\\nHDU summary by shape and index:\")\n",
    "for key, count in sorted(hdu_summary.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{key} : {count} files\")\n",
    "\n",
    "if empty_data_files:\n",
    "    print(\"\\nExample files with no data:\")\n",
    "    print(\"\\n\".join(empty_data_files[:5]))\n",
    "\n",
    "if unreadable_files:\n",
    "    print(\"\\nExample unreadable files:\")\n",
    "    print(\"\\n\".join(unreadable_files[:5]))"
   ],
   "id": "3b3a558a2f99fce4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "data_dir = \"/mnt/data/SDO-AIA/94\"\n",
    "file_pattern = \"*.fits\"\n",
    "saturation_threshold = 16000\n",
    "sample_limit = 10000\n",
    "num_workers = 16 # Adjust to number of CPU cores\n",
    "\n",
    "## List FITS files\n",
    "file_list = glob.glob(os.path.join(data_dir, file_pattern))\n",
    "print(f\"Found {len(file_list)} FITS files\")\n",
    "\n",
    "## Function to read and sample a FITS file\n",
    "def process_fits_file(file):\n",
    "    try:\n",
    "        with fits.open(file, memmap=True) as hdul:\n",
    "            data = None\n",
    "            for hdu in hdul:\n",
    "                if hasattr(hdu, 'data') and hdu.data is not None:\n",
    "                    data = hdu.data\n",
    "                    break\n",
    "            if data is not None:\n",
    "                flat = data.flatten()\n",
    "                if flat.size > sample_limit:\n",
    "                    sample = np.random.choice(flat, size=sample_limit, replace=False)\n",
    "                else:\n",
    "                    sample = flat\n",
    "                return sample\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "## Parallel processing ---\n",
    "sampled_pixels = []\n",
    "with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = {executor.submit(process_fits_file, file): file for file in file_list}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing in parallel\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            sampled_pixels.append(result)\n",
    "\n",
    "## Combine and analyze\n",
    "if sampled_pixels:\n",
    "    all_pixels = np.concatenate(sampled_pixels)\n",
    "    print(f\"Sampled total pixels: {all_pixels.size}\")\n",
    "\n",
    "    mean_val = np.mean(all_pixels)\n",
    "    std_val = np.std(all_pixels)\n",
    "    print(f\"Mean pixel value: {mean_val:.2f}, Std: {std_val:.2f}\")\n",
    "\n",
    "    ## Histogram with autumn colormap\n",
    "    bins = 500\n",
    "    hist_range = (0, np.percentile(all_pixels, 99.9))\n",
    "    counts, bin_edges = np.histogram(all_pixels, bins=bins, range=hist_range)\n",
    "    norm = Normalize(vmin=counts.min(), vmax=counts.max())\n",
    "    colors = cm.autumn(norm(counts))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for i in range(len(counts)):\n",
    "        ax.bar(bin_edges[i], counts[i],\n",
    "               width=bin_edges[i+1] - bin_edges[i],\n",
    "               color=colors[i], align='edge', edgecolor='black')\n",
    "    ax.axvline(saturation_threshold, color='red', linestyle='--', label='Saturation Threshold')\n",
    "    ax.set_xlabel('Pixel Intensity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('SDO/AIA 94Å Sampled Intensity Histogram (Colormap: autumn)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to plot.\")"
   ],
   "id": "59fdd3114034a461"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Histogram with Log Y-axis (Colormap: autumn)\n",
    "counts, bin_edges = np.histogram(all_pixels, bins=500, range=(0, np.percentile(all_pixels, 99.9)))\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "norm = Normalize(vmin=counts.min(), vmax=counts.max())\n",
    "colors = cm.autumn(norm(counts))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i in range(len(counts)):\n",
    "    ax.bar(bin_edges[i], counts[i],\n",
    "           width=bin_edges[i+1] - bin_edges[i],\n",
    "           color=colors[i], align='edge', edgecolor='black')\n",
    "\n",
    "ax.set_yscale('log')  # Log scale here\n",
    "ax.axvline(saturation_threshold, color='red', linestyle='--', label='Saturation Threshold')\n",
    "ax.set_xlabel('Pixel Intensity')\n",
    "ax.set_ylabel('Log Frequency')\n",
    "ax.set_title('SDO/AIA 94Å Histogram (Log Scale, Colormap: autumn)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3d7c91aed24f8de2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Remove zero or negative values before taking log\n",
    "valid_pixels = all_pixels[all_pixels > 0]\n",
    "# Logarithmic bins in intensity space\n",
    "log_bins = np.logspace(np.log10(valid_pixels.min()), np.log10(valid_pixels.max()), 500)\n",
    "# Histogram in log-space\n",
    "counts, bin_edges = np.histogram(valid_pixels, bins=log_bins)\n",
    "\n",
    "# Prepare log-log plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "log_bin_centers = np.log10(bin_centers)\n",
    "log_counts = np.log10(counts + 1)  # +1 to avoid log(0)\n",
    "\n",
    "# Colormap mapping by count\n",
    "norm = Normalize(vmin=counts.min(), vmax=counts.max())\n",
    "colors = cm.autumn(norm(counts))\n",
    "\n",
    "# Plot log-log histogram\n",
    "for i in range(len(counts)):\n",
    "    ax.bar(log_bin_centers[i], log_counts[i],\n",
    "           width=(log_bin_centers[1] - log_bin_centers[0]),\n",
    "           color=colors[i], edgecolor='black', align='center')\n",
    "\n",
    "ax.set_xlabel(\"log10(Pixel Intensity)\")\n",
    "ax.set_ylabel(\"log10(Frequency)\")\n",
    "ax.set_title(\"SDO/AIA 94Å Log-Log Histogram (Colormap: autumn)\")\n",
    "ax.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "eb85daed1967890a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ls",
   "id": "47d96437422a09cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "sample_size = 1000  # number of files to sample\n",
    "max_workers = 8  # optional for parallelization later\n",
    "\n",
    "# Collect and sample FITS files\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "if len(fits_files) < sample_size:\n",
    "    sample_files = fits_files\n",
    "else:\n",
    "    sample_files = random.sample(fits_files, sample_size)\n",
    "\n",
    "total_files = 0\n",
    "total_pixels = 0\n",
    "total_nans = 0\n",
    "files_with_nans = []\n",
    "\n",
    "print(f\"Checking for NaN values in {len(sample_files)} randomly sampled FITS files:\\n\")\n",
    "\n",
    "for file in tqdm(sample_files, desc=\"Checking NaNs\"):\n",
    "    try:\n",
    "        with fits.open(file, memmap=True) as hdul:\n",
    "            data = hdul[1].data if len(hdul) > 1 else hdul[0].data\n",
    "            num_pixels = data.size\n",
    "            num_nans = np.isnan(data).sum()\n",
    "        if num_nans > 0:\n",
    "            print(f\"{file.name}: NaNs = {num_nans} / {num_pixels} \"\n",
    "                  f\"({(num_nans / num_pixels * 100):.6f}%)\")\n",
    "            files_with_nans.append(file.name)\n",
    "        total_files += 1\n",
    "        total_pixels += num_pixels\n",
    "        total_nans += num_nans\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Failed to process - {e}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total sampled files checked: {total_files}\")\n",
    "print(f\"Total pixels checked: {total_pixels}\")\n",
    "print(f\"Total NaNs found: {total_nans} \"\n",
    "      f\"({(total_nans / total_pixels * 100 if total_pixels else 0):.6f}%)\")\n",
    "if files_with_nans:\n",
    "    print(\"\\nFiles with NaNs:\")\n",
    "    for fname in files_with_nans:\n",
    "        print(f\" - {fname}\")\n",
    "else:\n",
    "    print(\"\\nNo files with NaNs detected in the sampled set.\")"
   ],
   "id": "b546d28fb1ac1ec1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def check_nan_in_wavelength_folder(folder_path, wavelength, sample_size=1000):\n",
    "    folder = Path(folder_path)\n",
    "    fits_files = sorted(folder.glob(\"*.fits\"))\n",
    "\n",
    "    if len(fits_files) == 0:\n",
    "        print(f\"No FITS files found in {folder_path}\")\n",
    "        return\n",
    "    if len(fits_files) < sample_size:\n",
    "        sample_files = fits_files\n",
    "    else:\n",
    "        sample_files = random.sample(fits_files, sample_size)\n",
    "    total_files = 0\n",
    "    total_pixels = 0\n",
    "    total_nans = 0\n",
    "    files_with_nans = []\n",
    "    print(f\"\\nChecking NaN values for AIA {wavelength} Å ({len(sample_files)} sampled files):\")\n",
    "\n",
    "    for file in tqdm(sample_files, desc=f\"Checking {wavelength} Å\"):\n",
    "        try:\n",
    "            with fits.open(file, memmap=True) as hdul:\n",
    "                data = hdul[1].data if len(hdul) > 1 else hdul[0].data\n",
    "                num_pixels = data.size\n",
    "                num_nans = np.isnan(data).sum()\n",
    "\n",
    "            if num_nans > 0:\n",
    "                print(f\"{file.name}: NaNs = {num_nans} / {num_pixels} \"\n",
    "                      f\"({(num_nans / num_pixels * 100):.6f}%)\")\n",
    "                files_with_nans.append(file.name)\n",
    "            total_files += 1\n",
    "            total_pixels += num_pixels\n",
    "            total_nans += num_nans\n",
    "        except Exception as e:\n",
    "            print(f\"{file.name}: Failed to process - {e}\")\n",
    "\n",
    "    print(f\"\\nSummary for {wavelength} Å:\")\n",
    "    print(f\"Total sampled files checked: {total_files}\")\n",
    "    print(f\"Total pixels checked: {total_pixels}\")\n",
    "    print(f\"Total NaNs found: {total_nans} \"\n",
    "          f\"({(total_nans / total_pixels * 100 if total_pixels else 0):.6f}%)\")\n",
    "    if files_with_nans:\n",
    "        print(f\"\\nFiles with NaNs in {wavelength} Å:\")\n",
    "        for fname in files_with_nans:\n",
    "            print(f\" - {fname}\")\n",
    "    else:\n",
    "        print(f\"\\nNo files with NaNs detected in the sampled set for {wavelength} Å.\")\n",
    "\n",
    "#for reproducible sampling\n",
    "# random.seed(42)\n",
    "# Define wavelength folders\n",
    "base_path = \"/mnt/data/SDO-AIA\"\n",
    "wavelength_folders = {\n",
    "    \"94\": f\"{base_path}/94\",\n",
    "    \"131\": f\"{base_path}/131\",\n",
    "    \"171\": f\"{base_path}/171\",\n",
    "    \"193\": f\"{base_path}/193\",\n",
    "    \"211\": f\"{base_path}/211\",\n",
    "    \"304\": f\"{base_path}/304\",\n",
    "}\n",
    "\n",
    "# Run check for each wavelength\n",
    "for wavelength, folder_path in wavelength_folders.items():\n",
    "    check_nan_in_wavelength_folder(folder_path, wavelength, sample_size=1000)"
   ],
   "id": "3f4cd9fe1892614b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we want to normalize the exposure by dividing all the pixel intensities values by expose values",
   "id": "e51fdf23896af8ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "# Collect all FITS files\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "len(fits_files)"
   ],
   "id": "4ec320b6a9e0a27b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## check start and end dates in the folder\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "# Folder path\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "# Collect all FITS files\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "dates = []\n",
    "for file in fits_files:\n",
    "  # Extract date from filename\n",
    "    fname = file.stem  # removes .fits\n",
    "    # Example: '2023-08-05T21:10:00'\n",
    "    date_part = fname.split(\".\")[0]\n",
    "    dt = parse(date_part)\n",
    "    dates.append(dt)\n",
    "if dates:\n",
    "    first_date = min(dates)\n",
    "    last_date = max(dates)\n",
    "    print(\"Based on filenames:\")\n",
    "    print(f\"First (earliest) file date: {first_date.isoformat()}\")\n",
    "    print(f\"Last (latest) file date:    {last_date.isoformat()}\")\n",
    "    print(f\"Total files scanned: {len(dates)}\")"
   ],
   "id": "b7a0c1affbb01f4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Select the specific days for the normalization and histogram plot\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Define target dates\n",
    "target_dates = {\n",
    "    \"2023-07-02\",\n",
    "    \"2023-07-15\",\n",
    "    \"2023-07-31\",\n",
    "    \"2023-08-13\"\n",
    "}\n",
    "\n",
    "# Folder containing FITS files\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "specific_dates_files = []\n",
    "for file in fits_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        fname = file.stem  # '2023-07-02T21:10:00'\n",
    "        date_str = fname.split(\"T\")[0]  # '2023-07-02'\n",
    "        if date_str in target_dates:\n",
    "            specific_dates_files.append(file)\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Skipped - {e}\")\n",
    "print(f\"\\nTotal files matching the selected target dates: {len(specific_dates_files)}\")\n",
    "# print(\"Examples:\")\n",
    "# for f in specific_dates_files[:10]:\n",
    "#     print(f\" - {f.name}\")"
   ],
   "id": "a089379fa236a2e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Apply Normalization Step\n",
    "\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define target dates\n",
    "target_dates = {\n",
    "    \"2023-07-02\",\n",
    "    \"2023-07-15\",\n",
    "    \"2023-07-31\",\n",
    "    \"2023-08-13\"\n",
    "}\n",
    "\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "specific_dates_files = []\n",
    "specific_dates_files= fits_files[::len(fits_files)//10] ## Per Robert: testing code\n",
    "## Normalization\n",
    "all_normalized_data = []\n",
    "for file in tqdm(specific_dates_files, desc=\"Normalizing FITS files\", leave=True):\n",
    "    aia_map = sunpy.map.Map(file)\n",
    "    exptime = aia_map.exposure_time.value\n",
    "    normalized_data = aia_map.data / exptime\n",
    "    ## Mask invalid values\n",
    "    normalized_data = normalized_data[np.isfinite(normalized_data)]\n",
    "    normalized_data = normalized_data[normalized_data > 0]\n",
    "    all_normalized_data.append(normalized_data)\n",
    "    #print(file)\n",
    "\n",
    "if all_normalized_data:\n",
    "    try:\n",
    "        combined_data = np.concatenate(all_normalized_data)\n",
    "        print(f\"\\nTotal valid normalized pixels collected: {combined_data.size}\")\n",
    "    except MemoryError as e:\n",
    "        print(\"\\nMemoryError: Too many pixels to concatenate. Consider downsampling per file.\")\n",
    "else:\n",
    "    print(\"\\nNo valid data collected after normalization.\")"
   ],
   "id": "adc11a6d8bfea01d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalize the target_dates FITS files",
   "id": "74c6aa1fcff6f314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Apply Normalization Step\n",
    "\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define target dates\n",
    "target_dates = {\n",
    "    \"2023-07-02\",\n",
    "    #\"2023-07-15\",\n",
    "    # \"2023-07-31\",\n",
    "    # \"2023-08-13\"\n",
    "}\n",
    "\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "specific_dates_files = []\n",
    "for file in tqdm(fits_files, desc=\"Filtering files by date\", leave=True):\n",
    "    try:\n",
    "        fname = file.stem\n",
    "        if \"T\" in fname:\n",
    "            date_str = fname.split(\"T\")[0]\n",
    "            if date_str in target_dates:\n",
    "                specific_dates_files.append(file)\n",
    "        else:\n",
    "            tqdm.write(f\"{file.name}: Filename does not contain 'T', skipped.\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"{file.name}: Error during date parsing - {e}\")\n",
    "        continue\n",
    "print(f\"\\nTotal files matching target dates: {len(specific_dates_files)}\")\n",
    "\n",
    "## Normalization\n",
    "all_normalized_data = []\n",
    "for file in tqdm(specific_dates_files, desc=\"Normalizing FITS files\", leave=True):\n",
    "    try:\n",
    "        aia_map = sunpy.map.Map(file)\n",
    "        exptime = aia_map.exposure_time.value\n",
    "        normalized_data = aia_map.data / exptime\n",
    "        ## Mask invalid values\n",
    "        normalized_data = normalized_data[np.isfinite(normalized_data)]\n",
    "        normalized_data = normalized_data[normalized_data > 0]\n",
    "        all_normalized_data.append(normalized_data)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"{file.name}: Failed during normalization - {e}\")\n",
    "        continue\n",
    "if all_normalized_data:\n",
    "    try:\n",
    "        combined_data = np.concatenate(all_normalized_data)\n",
    "        print(f\"\\nTotal valid normalized pixels collected: {combined_data.size}\")\n",
    "    except MemoryError as e:\n",
    "        print(\"\\nMemoryError: Too many pixels to concatenate. Consider downsampling per file.\")\n",
    "else:\n",
    "    print(\"\\nNo valid data collected after normalization.\")"
   ],
   "id": "eb3e406455f5661e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "##Get the exposure time with SunPy for A94 folder data\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Folder with AIA 94 Å files\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "\n",
    "# Example: Compute and print the mean normalized intensity for each file\n",
    "for file in tqdm(fits_files, desc=\"Normalizing AIA 94 wavelength by exposure time\"):\n",
    "    try:\n",
    "        aia_map = sunpy.map.Map(file)\n",
    "        exptime = aia_map.exposure_time.value  # in seconds\n",
    "        # Normalize pixel data\n",
    "        normalized_data = aia_map.data / exptime\n",
    "        # Clean NaNs/Infs if needed\n",
    "        normalized_data = normalized_data[np.isfinite(normalized_data)]\n",
    "        normalized_data = normalized_data[normalized_data > 0]\n",
    "        # Example: Print mean normalized intensity\n",
    "        mean_val = np.mean(normalized_data)\n",
    "        print(f\"{file.name}: Mean normalized intensity = {mean_val:.2f}\")\n",
    "        #If we want to save normalized FITS for ML pipelines or consistency:\n",
    "        # from astropy.io import fits\n",
    "        # hdu = fits.PrimaryHDU(normalized_data, header=aia_map.meta)\n",
    "        # hdu.writeto(f\"/mnt/data/SDO-AIA/94_normalized/{file.name}\", overwrite=True)\n",
    "    except Exception as e:\n",
    "        print(f\"{file.name}: Failed - {e}\")"
   ],
   "id": "c33e8178ab30b394"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## plot the basic histogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Flatten the data and remove NaNs for a clean histogram\n",
    "data = aia_map.data.flatten()\n",
    "data = data[~np.isnan(data)]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data, bins=500, color='gray')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of Pixels')\n",
    "plt.title('Histogram of AIA Map Data')\n",
    "plt.show()"
   ],
   "id": "602f1dfeaf94a293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## plot the log-log histogram\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = aia_map.data.flatten()\n",
    "data = data[~np.isnan(data)]\n",
    "data = data[data > 0]  # Log requires positive values\n",
    "plt.figure()\n",
    "# Compute histogram without plotting first to enable log scale handling\n",
    "counts, bins = np.histogram(data, bins=500)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "plt.plot(bin_centers, counts)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Pixel Intensity (log scale)')\n",
    "plt.ylabel('Number of Pixels (log scale)')\n",
    "plt.title('Log-Log Histogram of AIA Map Data')\n",
    "plt.show()"
   ],
   "id": "6527f265ddbb2e86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "accordion = widgets.Accordion(children=[log_output])\n",
    "accordion.set_title(0, 'Test Dropdown')\n",
    "accordion.selected_index = None\n",
    "display(accordion)\n",
    "with log_output:\n",
    "    print(\"If you see this message inside a collapsible box, ipywidgets is working.\")"
   ],
   "id": "e054db4383021148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "accordion = widgets.Accordion(children=[log_output])\n",
    "accordion.set_title(0, 'Progress Details')\n",
    "accordion.selected_index = None\n",
    "display(accordion)\n",
    "\n",
    "for i in tqdm(range(5), desc=\"Test Progress\"):\n",
    "    with log_output:\n",
    "        print(f\"Processing step {i+1}/5\")\n",
    "    time.sleep(0.5)"
   ],
   "id": "adec4d27160d1132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sunpy.map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_aia_folder_histogram(\n",
    "    folder_path,\n",
    "    num_bins=500,\n",
    "    min_intensity=1,\n",
    "    max_intensity=1e4,\n",
    "    wavelength=\"94 Å\",\n",
    "    figsize=(14, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Incrementally process all FITS files in folder_path,\n",
    "    plot normal + log-log histograms without memory overflow.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str or Path): Path to the folder containing FITS files.\n",
    "        num_bins (int): Number of histogram bins.\n",
    "        min_intensity (float): Minimum intensity for binning (avoids log issues).\n",
    "        max_intensity (float): Maximum intensity for binning.\n",
    "        wavelength (str): For labeling plots.\n",
    "        figsize (tuple): Figure size.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    fits_files = sorted(folder.glob(\"*.fits\"))\n",
    "\n",
    "    # Collapsible log setup\n",
    "    log_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "    accordion = widgets.Accordion(children=[log_output])\n",
    "    accordion.set_title(0, 'Detailed FITS File Processing Log')\n",
    "    accordion.selected_index = None\n",
    "    display(accordion)\n",
    "\n",
    "    bins = np.logspace(np.log10(min_intensity), np.log10(max_intensity), num_bins + 1)\n",
    "    combined_counts = np.zeros(num_bins)\n",
    "\n",
    "    for file in tqdm(fits_files, desc=f\"Processing {wavelength} FITS files\"):\n",
    "        try:\n",
    "            aia_map = sunpy.map.Map(file)\n",
    "            data = aia_map.data.flatten()\n",
    "\n",
    "            num_nans = np.isnan(data).sum()\n",
    "            num_infs = np.isinf(data).sum()\n",
    "            data_min = np.nanmin(data)\n",
    "            data_max = np.nanmax(data)\n",
    "            with log_output:\n",
    "                print(f\"{file.name}: NaNs={num_nans}, Infs={num_infs}, Min={data_min}, Max={data_max}\")\n",
    "            data = data[~np.isnan(data)]\n",
    "            data = data[~np.isinf(data)]\n",
    "            data = data[data > 0]\n",
    "            counts, _ = np.histogram(data, bins=bins)\n",
    "            combined_counts += counts\n",
    "        except Exception as e:\n",
    "            with log_output:\n",
    "                print(f\"{file.name}: Failed to process - {e}\")\n",
    "    if combined_counts.sum() == 0:\n",
    "        with log_output:\n",
    "            print(\"No valid data collected for histogram.\")\n",
    "        return\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "    # Normal histogram\n",
    "    axs[0].plot(bin_centers, combined_counts, lw=1)\n",
    "    axs[0].set_xlabel('Pixel Intensity')\n",
    "    axs[0].set_ylabel('Number of Pixels')\n",
    "    axs[0].set_title(f'Normal Histogram of AIA {wavelength} Data')\n",
    "    axs[0].grid(True, ls=\":\")\n",
    "\n",
    "    # Log-log histogram\n",
    "    axs[1].plot(bin_centers, combined_counts, lw=1)\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].set_xlabel('Pixel Intensity (log scale)')\n",
    "    axs[1].set_ylabel('Number of Pixels (log scale)')\n",
    "    axs[1].set_title(f'Log-Log Histogram of AIA {wavelength} Data')\n",
    "    axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "b0e58c06c7033be1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_aia_folder_histogram(\n",
    "    folder_path=\"/mnt/data/SDO-AIA/94\",\n",
    "    num_bins=500,\n",
    "    min_intensity=1,\n",
    "    max_intensity=1e4,\n",
    "    wavelength=\"94 Å\"\n",
    ")"
   ],
   "id": "a47bc9443814afc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sunpy.map\n",
    "from sunpy.map import MapSequence\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_folder = Path(\"/mnt/data/SDO-AIA/94\")  # adjust as needed\n",
    "fits_files = sorted(data_folder.glob(\"*.fits\"))\n",
    "# Filter for specific dates if desired\n",
    "# target_dates = {\"2023-07-02\", \"2023-07-15\", \"2023-07-31\", \"2023-08-13\"}\n",
    "cleaned_maps = []\n",
    "\n",
    "# Normalization + Artifact Cleaning\n",
    "for file in tqdm(fits_files, desc=\"Normalizing & cleaning FITS\"):\n",
    "    try:\n",
    "        aia_map = sunpy.map.Map(file)\n",
    "        exptime = aia_map.exposure_time.value\n",
    "        # Exposure-time normalization\n",
    "        normalized_data = aia_map.data / exptime\n",
    "        # Mask artifacts:\n",
    "        mask = np.isfinite(normalized_data) & (normalized_data > 0)\n",
    "        valid_pixel_ratio = np.count_nonzero(mask) / mask.size\n",
    "        # Skip frames with too many artifacts\n",
    "        threshold = 0.99\n",
    "        if valid_pixel_ratio < threshold:\n",
    "            continue\n",
    "        # Create cleaned map preserving metadata\n",
    "        cleaned_map = sunpy.map.Map(np.where(mask, normalized_data, np.nan), aia_map.meta)\n",
    "        cleaned_maps.append(cleaned_map)\n",
    "    except Exception as e:\n",
    "        # Skip corrupted frames quietly\n",
    "        continue\n",
    "print(f\"\\nTotal cleaned, normalized frames ready: {len(cleaned_maps)}\")"
   ],
   "id": "7922d0cffde8b2c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if cleaned_maps:\n",
    "    cleaned_maps[0].plot()\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Sample Normalized, Cleaned AIA Frame\")\n",
    "    plt.show()"
   ],
   "id": "c96d721154e79706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "if cleaned_maps:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    def animate(i):\n",
    "        plt.clf()\n",
    "        cleaned_maps[i].plot()\n",
    "        plt.title(f\"AIA 94Å Frame {i+1}/{len(cleaned_maps)}\")\n",
    "        return fig,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(cleaned_maps), interval=50)\n",
    "\n",
    "    # Save as MP4\n",
    "    ani.save(\"aia_94_normalized_cleaned_movie.mp4\", writer=\"ffmpeg\", dpi=200)\n",
    "    print(\"Saved movie as aia_94_normalized_cleaned_movie.mp4\")\n",
    "\n",
    "    #Save as GIF\n",
    "    # ani.save(\"aia_94_normalized_cleaned_movie.gif\", writer=\"imagemagick\", dpi=100)\n",
    "    # print(\"Saved movie as aia_94_normalized_cleaned_movie.gif\")\n",
    "else:\n",
    "    print(\"No frames available to create a movie.\")\n"
   ],
   "id": "fad75d5c75c03da7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
