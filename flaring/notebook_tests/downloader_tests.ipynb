{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import argparse\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "from datetime import timedelta, datetime\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "import drms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from sunpy.io._fits import header_to_fits\n",
    "from sunpy.util import MetaDict\n",
    "from astropy import units as u\n",
    "\n",
    "\n",
    "class SDODownloader:\n",
    "    \"\"\"\n",
    "    Class to download SDO data from JSOC.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): Path to the directory where the downloaded data should be stored.\n",
    "        email (str): Email address for JSOC registration.\n",
    "        wavelengths (list): List of wavelengths to download.\n",
    "        n_workers (int): Number of worker threads for parallel download.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_path, email, wavelengths=['94', '131', '171', '193', '211', '304'], n_workers=8, cadence=60):\n",
    "        self.ds_path = base_path\n",
    "        self.wavelengths = [str(wl) for wl in wavelengths]\n",
    "        self.n_workers = n_workers\n",
    "        #[os.makedirs(os.path.join(base_path, wl), exist_ok=True) for wl in self.wavelengths + ['6173']]\n",
    "        [os.makedirs(os.path.join(base_path, wl), exist_ok=True) for wl in self.wavelengths]\n",
    "        self.drms_client = drms.Client(email=email)\n",
    "        self.cadence = cadence\n",
    "\n",
    "    def download(self, sample):\n",
    "        \"\"\"\n",
    "        Download the data from JSOC.\n",
    "\n",
    "        Args:\n",
    "            sample (tuple): Tuple containing the header, segment and time information.\n",
    "\n",
    "        Returns:\n",
    "            str: Path to the downloaded file.\n",
    "        \"\"\"\n",
    "        header, segment, t = sample\n",
    "        try:\n",
    "            dir = os.path.join(self.ds_path, '%d' % header['WAVELNTH'])\n",
    "            map_path = os.path.join(dir, '%s.fits' % t.isoformat('T', timespec='seconds'))\n",
    "            if os.path.exists(map_path):\n",
    "                return map_path\n",
    "            # load map\n",
    "            url = 'http://jsoc.stanford.edu' + segment\n",
    "            request.urlretrieve(url, filename=map_path)\n",
    "\n",
    "            header['DATE_OBS'] = header['DATE__OBS']\n",
    "            header = header_to_fits(MetaDict(header))\n",
    "            with fits.open(map_path, 'update') as f:\n",
    "                hdr = f[1].header\n",
    "                for k, v in header.items():\n",
    "                    if pd.isna(v):\n",
    "                        continue\n",
    "                    hdr[k] = v\n",
    "                f.verify('silentfix')\n",
    "\n",
    "            return map_path\n",
    "        except Exception as ex:\n",
    "            logging.info('Download failed: %s (requeue)' % header['DATE__OBS'])\n",
    "            logging.info(ex)\n",
    "            raise ex\n",
    "\n",
    "    def downloadDate(self, date):\n",
    "        \"\"\"\n",
    "        Download the data for the given date.\n",
    "\n",
    "        Args:\n",
    "            date (datetime): The date for which the data should be downloaded.\n",
    "\n",
    "        Returns:\n",
    "            list: List of paths to the downloaded files.\n",
    "        \"\"\"\n",
    "        id = date.isoformat()\n",
    "\n",
    "        logging.info('Start download: %s' % id)\n",
    "        # query Magnetogram\n",
    "        time_param = '%sZ' % date.isoformat('_', timespec='seconds')\n",
    "        #ds_hmi = 'hmi.M_720s[%s]{magnetogram}' % time_param\n",
    "        #keys_hmi = self.drms_client.keys(ds_hmi)\n",
    "        #header_hmi, segment_hmi = self.drms_client.query(ds_hmi, key=','.join(keys_hmi), seg='magnetogram')\n",
    "        #if len(header_hmi) != 1 or np.any(header_hmi.QUALITY != 0):\n",
    "        #    self.fetchDataFallback(date)\n",
    "        #    return\n",
    "\n",
    "        # query EUV\n",
    "        time_param = '%sZ' % date.isoformat('_', timespec='seconds')\n",
    "        ds_euv = 'aia.lev1_euv_12s[%s][%s]{image}' % (time_param, ','.join(self.wavelengths))\n",
    "        keys_euv = self.drms_client.keys(ds_euv)\n",
    "        header_euv, segment_euv = self.drms_client.query(ds_euv, key=','.join(keys_euv), seg='image')\n",
    "        if len(header_euv) != len(self.wavelengths) or np.any(header_euv.QUALITY != 0):\n",
    "            self.fetchDataFallback(date)\n",
    "            return\n",
    "\n",
    "        queue = []\n",
    "        #for (idx, h), s in zip(header_hmi.iterrows(), segment_hmi.magnetogram):\n",
    "        #    queue += [(h.to_dict(), s, date)]\n",
    "        for (idx, h), s in zip(header_euv.iterrows(), segment_euv.image):\n",
    "            queue += [(h.to_dict(), s, date)]\n",
    "\n",
    "        with multiprocessing.Pool(self.n_workers) as p:\n",
    "            p.map(self.download, queue)\n",
    "        logging.info('Finished: %s' % id)\n",
    "\n",
    "    def fetchDataFallback(self, date):\n",
    "        \"\"\"\n",
    "        Download the data for the given date using fallback.\n",
    "\n",
    "        Args:\n",
    "            date (datetime): The date for which the data should be downloaded.\n",
    "\n",
    "        Returns:\n",
    "            list: List of paths to the downloaded files.\n",
    "        \"\"\"\n",
    "        id = date.isoformat()\n",
    "\n",
    "        logging.info('Fallback download: %s' % id)\n",
    "        # query Magnetogram\n",
    "        t = date - timedelta(hours=24)\n",
    "        ds_hmi = 'hmi.M_720s[%sZ/12h@720s]{magnetogram}' % t.replace(tzinfo=None).isoformat('_', timespec='seconds')\n",
    "        keys_hmi = self.drms_client.keys(ds_hmi)\n",
    "        header_tmp, segment_tmp = self.drms_client.query(ds_hmi, key=','.join(keys_hmi), seg='magnetogram')\n",
    "        assert len(header_tmp) != 0, 'No data found!'\n",
    "        date_str = header_tmp['DATE__OBS'].replace('MISSING', '').str.replace('60', '59')  # fix date format\n",
    "        date_diff = np.abs(pd.to_datetime(date_str).dt.tz_localize(None) - date)\n",
    "        # sort and filter\n",
    "        header_tmp['date_diff'] = date_diff\n",
    "        header_tmp.sort_values('date_diff')\n",
    "        segment_tmp['date_diff'] = date_diff\n",
    "        segment_tmp.sort_values('date_diff')\n",
    "        cond_tmp = header_tmp.QUALITY == 0\n",
    "        header_tmp = header_tmp[cond_tmp]\n",
    "        segment_tmp = segment_tmp[cond_tmp]\n",
    "        assert len(header_tmp) > 0, 'No valid quality flag found'\n",
    "        # replace invalid\n",
    "        header_hmi = header_tmp.iloc[0].drop('date_diff')\n",
    "        segment_hmi = segment_tmp.iloc[0].drop('date_diff')\n",
    "        ############################################################\n",
    "        # query EUV\n",
    "        header_euv, segment_euv = [], []\n",
    "        t = date - timedelta(hours=6)\n",
    "        for wl in self.wavelengths:\n",
    "            euv_ds = 'aia.lev1_euv_12s[%sZ/12h@12s][%s]{image}' % (\n",
    "                t.replace(tzinfo=None).isoformat('_', timespec='seconds'), wl)\n",
    "            keys_euv = self.drms_client.keys(euv_ds)\n",
    "            header_tmp, segment_tmp = self.drms_client.query(euv_ds, key=','.join(keys_euv), seg='image')\n",
    "            assert len(header_tmp) != 0, 'No data found!'\n",
    "            date_str = header_tmp['DATE__OBS'].replace('MISSING', '').str.replace('60', '59')  # fix date format\n",
    "            date_diff = (pd.to_datetime(date_str).dt.tz_localize(None) - date).abs()\n",
    "            # sort and filter\n",
    "            header_tmp['date_diff'] = date_diff\n",
    "            header_tmp.sort_values('date_diff')\n",
    "            segment_tmp['date_diff'] = date_diff\n",
    "            segment_tmp.sort_values('date_diff')\n",
    "            cond_tmp = header_tmp.QUALITY == 0\n",
    "            header_tmp = header_tmp[cond_tmp]\n",
    "            segment_tmp = segment_tmp[cond_tmp]\n",
    "            assert len(header_tmp) > 0, 'No valid quality flag found'\n",
    "            # replace invalid\n",
    "            header_euv.append(header_tmp.iloc[0].drop('date_diff'))\n",
    "            segment_euv.append(segment_tmp.iloc[0].drop('date_diff'))\n",
    "\n",
    "        queue = []\n",
    "        #queue += [(header_hmi.to_dict(), segment_hmi.magnetogram, date)]\n",
    "        for h, s in zip(header_euv, segment_euv):\n",
    "            queue += [(h.to_dict(), s.image, date)]\n",
    "\n",
    "        with multiprocessing.Pool(self.n_workers) as p:\n",
    "            p.map(self.download, queue)\n",
    "\n",
    "        logging.info('Finished: %s' % id)\n",
    "\n"
   ],
   "id": "c833edbfe4e3e116"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Download SDO data from JSOC with quality check and fallback')\n",
    "    parser.add_argument('--download_dir', type=str, help='path to the download directory.')\n",
    "    parser.add_argument('--email', type=str, help='registered email address for JSOC.')\n",
    "    parser.add_argument('--start_date', type=str, help='start date in format YYYY-MM-DD.')\n",
    "    parser.add_argument('--end_date', type=str, help='end date in format YYYY-MM-DD.', required=False,\n",
    "                        default=str(datetime.now()).split(' ')[0])\n",
    "    parser.add_argument('--cadence', type=int, help='cadence in minutes.', required=False, default=60)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    download_dir = args.download_dir\n",
    "    start_date = args.start_date\n",
    "    end_date = args.end_date\n",
    "    cadence = args.cadence\n",
    "\n",
    "    [os.makedirs(os.path.join(download_dir, str(c)), exist_ok=True) for c in [94, 131, 171, 193, 211, 304]]\n",
    "    downloader = SDODownloader(base_path=download_dir, email=args.email)\n",
    "    start_date_datetime = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    #end_date = datetime.now()\n",
    "    end_date_datetime = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    for d in [start_date_datetime + i * timedelta(minutes=1) for i in\n",
    "              range((end_date_datetime - start_date_datetime) // timedelta(minutes=1))]:\n",
    "        downloader.downloadDate(d)"
   ],
   "id": "9c2168664ef3bc57"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
